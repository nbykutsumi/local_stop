{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((43061, 273), (43061, 1))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pylab as pl\n",
    "import tensorflow as tf\n",
    "import matplotlib.gridspec as gridspec\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "#train = np.concatenate([ np.loadtxt('train3_12345.txt' ), \n",
    "#                         np.loadtxt('train3_6789.txt'  ), \n",
    "#                         np.loadtxt('train3_101112.txt')])\n",
    "#label = np.concatenate([ np.loadtxt('label3_12345.txt' ), \n",
    "#                         np.loadtxt('label3_6789.txt'  ), \n",
    "#                         np.loadtxt('label3_101112.txt')]).reshape(-1,1)\n",
    "\n",
    "train = np.concatenate([ np.loadtxt('train3_12345.txt' ) \n",
    "                        ])\n",
    "label = np.concatenate([ np.loadtxt('label3_12345.txt' )\n",
    "                         ]).reshape(-1,1)\n",
    "\n",
    "train.shape, label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n",
      "(43061, 39)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/utsumi/miniconda2/envs/py27/lib/python2.7/site-packages/ipykernel_launcher.py:4: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "cov = 1/len(train)*np.dot((train-train.mean(0)).T, train-train.mean(0))\n",
    "u,s,v = np.linalg.svd(cov)\n",
    "restriction = 39\n",
    "print(s[:restriction].sum()/s.sum())\n",
    "U = u[:,:restriction]\n",
    "reduction = np.dot(train, U)\n",
    "Max, Min = np.max(label), np.min(label)\n",
    "print(reduction.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FFN(TraX, TraY, TesX, TesY, learning_rate, epochs, batch_size, dim, act): \n",
    "    fn1 = tf.nn.sigmoid\n",
    "    fn2 = tf.nn.relu\n",
    "    def fn3(x):\n",
    "        return x/(1+np.abs(x))\n",
    "    ac  = [fn1,fn3,fn1,fn3,fn1,fn1,fn1,fn1,fn1,fn1,fn1,fn1,fn1,fn1] # number of entry = len(dim) - 2\n",
    "    total_batch = int(len(TraX)/batch_size) + 1\n",
    "    Xdata = [ TraX[i*batch_size:(i+1)*batch_size] for i in range(total_batch) ]\n",
    "    Ydata = [ TraY[i*batch_size:(i+1)*batch_size] for i in range(total_batch) ]\n",
    "    \n",
    "    tf.reset_default_graph()\n",
    "    X = tf.placeholder(tf.float32, [None, TraX.shape[1]])\n",
    "    Y = tf.placeholder(tf.float32, [None, TraY.shape[1]])\n",
    "        \n",
    "    W = [ tf.Variable(tf.random_normal([dim[i], dim[i+1]])) for i in range(len(dim) - 1) ]\n",
    "    b = [ tf.Variable(tf.random_normal([dim[i+1]]))         for i in range(len(dim) - 1) ]\n",
    "    A = [ X ]\n",
    "    for i in range(len(dim) - 2):\n",
    "        A.append(ac[i](tf.matmul(A[-1], W[i]) + b[i]))\n",
    "    A.append(tf.matmul(A[-1], W[-1]) + b[-1])  \n",
    "    if act == 0:\n",
    "        cost = tf.sqrt(tf.reduce_mean(tf.reduce_mean(tf.square(Y - A[-1]) ))) \n",
    "    if act == 1:\n",
    "        cost = tf.sqrt(tf.reduce_mean(tf.reduce_mean(tf.square(Y - A[-1])*error_function(Y,label,100,12,1,5) ))) \n",
    "    gogo = tf.train.AdamOptimizer(learning_rate).minimize(cost)\n",
    "    real = tf.placeholder(tf.float32, [None, TraY.shape[1]])\n",
    "    pred = tf.placeholder(tf.float32, [None, TraY.shape[1]])\n",
    "    rmse = tf.sqrt(tf.reduce_mean(tf.reduce_mean(tf.square(real - pred))))\n",
    "    sess = tf.Session()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for epoch in range(epochs):    \n",
    "        for i in range(total_batch):\n",
    "            feed1 = {X:Xdata[i], Y:Ydata[i]}\n",
    "            sess.run(gogo, feed_dict = feed1)\n",
    "            training_error = sess.run(cost, feed_dict = feed1)\n",
    "            prediction     = sess.run(A[-1], feed_dict = {X:TesX})\n",
    "            test_error     = sess.run(rmse, feed_dict = {real:TesY, pred:prediction})\n",
    "        if epoch % int(epochs/5) == 0:    \n",
    "            print('Training Error:',training_error,'and','Testing Error:', test_error)\n",
    "    return prediction\n",
    "def Figure(Label, Prediction, bins):\n",
    "    recover_testY = (Max-Min)*Label.flatten()      + Min\n",
    "    recover_pred  = (Max-Min)*Prediction.flatten() + Min\n",
    "    pl.figure(figsize=(15,15))\n",
    "    gs = gridspec.GridSpec(2,2, width_ratios=[1,1], height_ratios=[1,1])\n",
    "    \n",
    "    pl.subplot(gs[0,:])\n",
    "    pl.plot(recover_testY/1000, c='r', label ='Observation')\n",
    "    pl.plot(recover_pred /1000, c='b', label ='Prediction')\n",
    "    pl.ylabel('height(km)')\n",
    "    pl.legend()\n",
    "    print('RMSE:'     , np.round(rmse(Label, Prediction) , 4))\n",
    "    print('real RMSE:', np.round(Rmse(Label, Prediction) , 4))\n",
    "    print('CC:'       , np.round(  cc(Label, Prediction) , 4))\n",
    "    \n",
    "    pl.subplot(gs[2]) # values prediction and testY are between -4 and 4\n",
    "    aa = recover_pred\n",
    "    bb = recover_testY\n",
    "    interval           = np.array([ Min + (Max - Min)/bins*i for i in range(bins+1) ])\n",
    "    interval1          = np.array([ Min + (Max - Min)/bins*i for i in range(bins+1) ])\n",
    "    revised_interval   = interval[:-1]  + (Max - Min)/(2*bins)\n",
    "    revised_interval1  = interval1[:-1] + (Max - Min)/(2*bins)\n",
    "    cumulative_number  = []\n",
    "    cumulative_number1 = []\n",
    "    for i in range(bins):\n",
    "        cumulative_number.append(  (aa < interval[i+1] ).sum() - (aa < interval[i] ).sum() )\n",
    "        cumulative_number1.append( (bb < interval1[i+1]).sum() - (bb < interval1[i]).sum() )\n",
    "    pl.plot(revised_interval/1000          , cumulative_number   , color='green', alpha=0.5, label='Prediction')    \n",
    "    pl.fill_between(revised_interval/1000  , cumulative_number, 0, color='green', alpha=0.5)\n",
    "    pl.plot(revised_interval1/1000         , cumulative_number1  , color='red'  , alpha=0.5 ,label='Observation')    \n",
    "    pl.fill_between(revised_interval1/1000 ,cumulative_number1, 0, color='red'  , alpha=0.5)\n",
    "    pl.ylabel('number of samples')\n",
    "    pl.xlabel('height(km)')\n",
    "    pl.legend() \n",
    "    pl.title('Distribution')\n",
    "    pl.legend()\n",
    "    \n",
    "    pl.subplot(gs[3])\n",
    "    pl.scatter(recover_testY/1000, recover_pred/1000,s=3)\n",
    "    pl.plot(np.arange(18000)/1000,np.arange(18000)/1000,c='black',linestyle = ':')\n",
    "    pl.axis([0,18,0,18])\n",
    "    pl.xticks([0,5,10,15])\n",
    "    pl.yticks([0,5,10,15])\n",
    "    pl.xlabel('Observation(km)')\n",
    "    pl.ylabel('Prediction(km)')\n",
    "    pl.title('Correlation')\n",
    "    pl.grid()\n",
    "def error_function(x, data, bins, degree, Min, Max):\n",
    "    vec       = ((data - np.min(data,0))/(np.max(data,0)-np.min(data,0)))\n",
    "    interval  = [ i/bins for i in range(bins + 1)]\n",
    "    frequency = np.array([ ((vec<=interval[i+1]).sum() - (vec<interval[i]).sum())/len(vec) for i in range(bins) ])\n",
    "    xx        = np.arange(bins)/(bins - 1)\n",
    "    mat       = np.concatenate([(xx**i).reshape(-1,1) for i in range(degree)], axis=1)\n",
    "    coef      = np.dot(np.linalg.inv(np.dot(mat.T,mat)), np.dot(mat.T, frequency))\n",
    "    poly      = 1 - sum([coef[i]*(x**i) for i in range(degree)])\n",
    "    values    = 1 - sum([coef[i]*(xx**i) for i in range(degree)])\n",
    "    M, N      = np.max(values), np.min(values)\n",
    "    return (Max - Min)/(M - N)*(poly - N) + Min \n",
    "def uniformize(reduction, label):\n",
    "    mat = np.concatenate([reduction, label], axis=1)\n",
    "    temporary = []\n",
    "    for i in range(mat.shape[1]):\n",
    "        a = np.arange(len(mat)).reshape(-1,1)\n",
    "        b = np.concatenate([a,mat[:,[i]]], axis=1)\n",
    "        c = b[b[:,1].argsort()]\n",
    "        c[:,1] = np.arange(len(mat))/(len(mat)-1)\n",
    "        d = c[c[:,0].argsort()]\n",
    "        temporary.append(d[:,1])\n",
    "    input_data = (np.array(temporary).T)[:, :-1]\n",
    "    target     = (np.array(temporary).T)[:,[-1]]\n",
    "    return input_data, target\n",
    "def rmse(x,y):\n",
    "    x = x.flatten()\n",
    "    y = y.flatten()\n",
    "    return np.sqrt((((x-y))**2).mean())\n",
    "def Rmse(x,y):\n",
    "    return np.sqrt( ( ( ((Max-Min)*x+Min).flatten()-((Max-Min)*y+Min).flatten() )**2 ).mean() )\n",
    "def cc(x,y):\n",
    "    return np.corrcoef( x.flatten(), y.flatten() )[0,1]\n",
    "def sort(x):\n",
    "    return np.sort(x.flatten())\n",
    "def unit(x):\n",
    "    return (x-np.min(x,0))/(np.max(x,0)-np.min(x,0))\n",
    "def f_act(x):\n",
    "    degree = 12\n",
    "    y_val = np.sort(unit(label.flatten()))\n",
    "    X     = (np.arange(len(y_val))/(len(y_val)-1) )\n",
    "    mat   = np.concatenate([(X**i).reshape(-1,1) for i in range(degree)], axis=1)\n",
    "    coef  = np.dot(np.linalg.inv(np.dot(mat.T,mat)), np.dot(mat.T, y_val))\n",
    "    poly  = sum([coef[i]*(x**i) for i in range(degree)])\n",
    "    return poly\n",
    "x = np.arange(100001)/100000\n",
    "pl.figure(figsize=(14,4))\n",
    "pl.subplot(131)\n",
    "pl.plot(x,f_act(x))\n",
    "pl.plot(np.arange(len(label))/(len(label)-1),np.sort(unit(label.flatten())))\n",
    "pl.subplot(132)\n",
    "pl.plot(x, error_function(x, label, 100, 12, 1, 10))\n",
    "pl.subplot(133)\n",
    "_,_,_ = pl.hist(label, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As usual\n",
    "Train, Label = unit(reduction), unit(label)\n",
    "ntrain       = int(0.7*len(reduction))\n",
    "trainX, trainY, testX, testY = Train[:ntrain], Label[:ntrain], Train[ntrain:], Label[ntrain:]\n",
    "print(trainX.shape, trainY.shape, testX.shape, testY.shape)\n",
    "dim = [trainX.shape[1], 30, 30, 30,10, trainY.shape[1]]\n",
    "rmse1,cc1 = [],[]\n",
    "for i in range(20):\n",
    "    prediction   = FFN(trainX, trainY, testX, testY, 0.005, 50, 1024*4, dim, 0)\n",
    "    rmse1.append(Rmse(prediction, testY))\n",
    "    cc1.append(cc(prediction, testY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply error function\n",
    "Train, Label = unit(reduction), unit(label)\n",
    "ntrain       = int(0.7*len(reduction))\n",
    "trainX, trainY, testX, testY = Train[:ntrain], Label[:ntrain], Train[ntrain:], Label[ntrain:]\n",
    "print(trainX.shape, trainY.shape, testX.shape, testY.shape)\n",
    "dim = [trainX.shape[1], 30, 30, 30,10, trainY.shape[1]]\n",
    "rmse2, cc2 = [], []\n",
    "for i in range(20):\n",
    "    prediction   = FFN(trainX, trainY, testX, testY, 0.005, 50, 1024*4, dim, 1)\n",
    "    rmse2.append(Rmse(prediction, testY))\n",
    "    cc2.append(cc(prediction, testY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sort(rmse1)[:10].mean(), np.sort(rmse2)[:10].mean(), np.sort(cc1)[10:].mean(), np.sort(cc2)[10:].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As usual\n",
    "Train, Label = unit(reduction), unit(label)\n",
    "ntrain       = int(0.7*len(reduction))\n",
    "trainX, trainY, testX, testY = Train[:ntrain], Label[:ntrain], Train[ntrain:], Label[ntrain:]\n",
    "print(trainX.shape, trainY.shape, testX.shape, testY.shape)\n",
    "dim = [trainX.shape[1], 30, 30, 30,10, trainY.shape[1]]\n",
    "prediction   = FFN(trainX, trainY, testX, testY, 0.005, 50, 1024*4, dim, 0)\n",
    "Figure(testY, prediction, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply error function\n",
    "Train, Label = unit(reduction), unit(label)\n",
    "ntrain       = int(0.7*len(reduction))\n",
    "trainX, trainY, testX, testY = Train[:ntrain], Label[:ntrain], Train[ntrain:], Label[ntrain:]\n",
    "print(trainX.shape, trainY.shape, testX.shape, testY.shape)\n",
    "dim = [trainX.shape[1], 30, 30, 30,10, trainY.shape[1]]\n",
    "prediction   = FFN(trainX, trainY, testX, testY, 0.005, 50, 1024*4, dim, 1)\n",
    "Figure(testY, prediction, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
